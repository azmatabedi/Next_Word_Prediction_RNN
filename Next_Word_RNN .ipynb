{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Next_Word_RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdu7bem4zfse"
      },
      "source": [
        "#Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey2ZBFa8yHPc"
      },
      "source": [
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential,load_model\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.core import Dense ,Activation\n",
        "from keras.optimizers import RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kASOAPoOzenk"
      },
      "source": [
        "text=\"\"\"Facebook is a website which allows users, who sign-up for free profiles, to connect with friends, work colleagues or people they do not know, online.\\n It allows users to share pictures, music, videos, and articles, as well as their own thoughts and opinions with however many people they like.\"\"\""
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHqR1UB_1YK2",
        "outputId": "365d306d-62da-4544-b1dc-d01d69024774"
      },
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n",
        "encoded_data=tokenizer.texts_to_sequences([text])[0]\n",
        "encoded_data"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 1,\n",
              " 2,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 3,\n",
              " 20,\n",
              " 4,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 5,\n",
              " 6,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 7,\n",
              " 34,\n",
              " 8,\n",
              " 35,\n",
              " 8,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 7,\n",
              " 39,\n",
              " 4,\n",
              " 40,\n",
              " 41,\n",
              " 5,\n",
              " 6,\n",
              " 42]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh5kedSm15qZ",
        "outputId": "0a12e84f-ef4b-4b7c-96e0-7810a97afb18"
      },
      "source": [
        "vocab_size=len(tokenizer.word_index)+1\n",
        "print('Vocabulary Size ' ,vocab_size)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary Size  43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNt4q_Z14nA7"
      },
      "source": [
        "#Create the sequence of words to fit the model with one words as input and one word as the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PLCyP2-410T",
        "outputId": "d79d584c-6f52-4d49-b0c6-65c0c340976d"
      },
      "source": [
        "sequences =list ()\n",
        "for i in range(1,len(encoded_data)):\n",
        "  sequence=encoded_data[i-1:i+1]\n",
        "  sequences.append(sequence)\n",
        "print('Total Sequence %d',len(sequences))  "
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequence %d 49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mRg151g6FKM",
        "outputId": "5bd26de6-a511-4f5d-f69a-767bdce59349"
      },
      "source": [
        "print(sequences)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9, 10], [10, 11], [11, 12], [12, 13], [13, 1], [1, 2], [2, 14], [14, 15], [15, 16], [16, 17], [17, 18], [18, 19], [19, 3], [3, 20], [20, 4], [4, 21], [21, 22], [22, 23], [23, 24], [24, 5], [5, 6], [6, 25], [25, 26], [26, 27], [27, 28], [28, 29], [29, 1], [1, 2], [2, 3], [3, 30], [30, 31], [31, 32], [32, 33], [33, 7], [7, 34], [34, 8], [8, 35], [35, 8], [8, 36], [36, 37], [37, 38], [38, 7], [7, 39], [39, 4], [4, 40], [40, 41], [41, 5], [5, 6], [6, 42]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oy7ViggUQS2H"
      },
      "source": [
        "#split the sequence the into X and Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm3tUFNr6Qyv"
      },
      "source": [
        "sequences=array(sequences)\n",
        "x,y=sequences[:,0],sequences[:,1]\n"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IFlkaym_QOO",
        "outputId": "267fdae0-e749-4bc3-e8fc-892c8475d88f"
      },
      "source": [
        "print(x[:5])"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 9 10 11 12 13]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlSrJhYd__fx"
      },
      "source": [
        "y=to_categorical(y,num_classes=vocab_size)"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pabEHt5ZQ6pT"
      },
      "source": [
        "#Build the Model RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO2dIRRhA2R2",
        "outputId": "6a54ce39-dca3-4802-f516-e6297eeecd4e"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,10,input_length=1))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(vocab_size,activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 1, 10)             430       \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 50)                12200     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 43)                2193      \n",
            "=================================================================\n",
            "Total params: 14,823\n",
            "Trainable params: 14,823\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNEsh26SDJwD"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV2sPJ4yRCbD"
      },
      "source": [
        "#Train the  model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EVVe5ECDhP6",
        "outputId": "00646aa5-7805-4428-849a-2b4470034ea5"
      },
      "source": [
        "model.fit(x,y,epochs=100)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 2s 6ms/step - loss: 3.7616 - accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.7604 - accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.7595 - accuracy: 0.0240\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7586 - accuracy: 0.0480\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7579 - accuracy: 0.0480\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7570 - accuracy: 0.0544\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.7562 - accuracy: 0.0889\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.7554 - accuracy: 0.1097\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7543 - accuracy: 0.1577\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7535 - accuracy: 0.1473\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7526 - accuracy: 0.1369\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7516 - accuracy: 0.1265\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.7511 - accuracy: 0.1473\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.7493 - accuracy: 0.1609\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.7486 - accuracy: 0.1818\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.7464 - accuracy: 0.1818\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.7468 - accuracy: 0.1954\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7463 - accuracy: 0.1881\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.7450 - accuracy: 0.2466\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.7425 - accuracy: 0.2466\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.7419 - accuracy: 0.2466\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 3.7401 - accuracy: 0.2466\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 3.7396 - accuracy: 0.2634\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.7374 - accuracy: 0.2738\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.7351 - accuracy: 0.2842\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7327 - accuracy: 0.3051\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.7314 - accuracy: 0.2946\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.7304 - accuracy: 0.2770\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7270 - accuracy: 0.3187\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7263 - accuracy: 0.3323\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7225 - accuracy: 0.3427\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.7229 - accuracy: 0.3010\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.7218 - accuracy: 0.2906\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.7169 - accuracy: 0.3219\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7161 - accuracy: 0.3010\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.7107 - accuracy: 0.3323\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7062 - accuracy: 0.3427\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.7089 - accuracy: 0.2906\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.7034 - accuracy: 0.3114\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.6965 - accuracy: 0.3323\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.6975 - accuracy: 0.3010\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.6896 - accuracy: 0.3323\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.6889 - accuracy: 0.3219\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.6830 - accuracy: 0.3219\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.6801 - accuracy: 0.3219\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.6738 - accuracy: 0.3323\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.6720 - accuracy: 0.3010\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.6683 - accuracy: 0.3010\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.6555 - accuracy: 0.3531\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.6531 - accuracy: 0.3219\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.6473 - accuracy: 0.3323\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.6411 - accuracy: 0.3323\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.6323 - accuracy: 0.3427\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.6277 - accuracy: 0.3323\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.6195 - accuracy: 0.3323\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.6130 - accuracy: 0.3323\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.6076 - accuracy: 0.3114\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.5964 - accuracy: 0.3427\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.5894 - accuracy: 0.3323\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.5828 - accuracy: 0.3219\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.5689 - accuracy: 0.3427\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.5624 - accuracy: 0.3323\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5532 - accuracy: 0.2978\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.5399 - accuracy: 0.3323\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5393 - accuracy: 0.3010\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.5301 - accuracy: 0.3114\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 3.5111 - accuracy: 0.3323\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 3.5020 - accuracy: 0.3010\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.4845 - accuracy: 0.3114\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 3.4801 - accuracy: 0.3010\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4627 - accuracy: 0.3114\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4449 - accuracy: 0.3219\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.4161 - accuracy: 0.3739\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4188 - accuracy: 0.2978\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.3900 - accuracy: 0.3187\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.3872 - accuracy: 0.3082\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.3736 - accuracy: 0.2978\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 3.3498 - accuracy: 0.3323\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.3288 - accuracy: 0.3563\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.3200 - accuracy: 0.3219\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.3190 - accuracy: 0.3010\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.2877 - accuracy: 0.3355\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.2696 - accuracy: 0.3250\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.2350 - accuracy: 0.3563\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 3.2363 - accuracy: 0.3250\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.2066 - accuracy: 0.3595\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.1828 - accuracy: 0.3699\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.1721 - accuracy: 0.3491\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.1344 - accuracy: 0.3803\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 3.1208 - accuracy: 0.3595\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.0847 - accuracy: 0.3803\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 3.0878 - accuracy: 0.3595\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 3.0672 - accuracy: 0.3731\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 3.0206 - accuracy: 0.4043\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 2.9968 - accuracy: 0.4043\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.9774 - accuracy: 0.3939\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 2.9603 - accuracy: 0.3595\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 2.9134 - accuracy: 0.3907\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.9033 - accuracy: 0.3595\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 2.8708 - accuracy: 0.3803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5cdef39650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuprOUe5RIzF"
      },
      "source": [
        "#Genetare_sqe function helps you to generate the next word "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eVJ5EqPDm99"
      },
      "source": [
        "def generate_seq(model,tokenizer,enter_text,n_pred):\n",
        "  in_text,result=enter_text,enter_text\n",
        "  for i in range(n_pred):\n",
        "    encoded=tokenizer.texts_to_sequences([in_text])[0]\n",
        "    encoded=array(encoded)\n",
        "    yhat=np.argmax(model.predict(encoded),axis=-1)\n",
        "    \n",
        "    out_word=' '\n",
        "    for word,index in tokenizer.word_index.items():\n",
        "      if index==yhat:\n",
        "        out_word=word\n",
        "        break\n",
        "    in_text,result=out_word,result +' '+ out_word\n",
        "    return result"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiXxcIZ5GjNB",
        "outputId": "cca9931f-04c2-4d78-f767-b436c8a6d925"
      },
      "source": [
        "print(generate_seq(model,tokenizer,'users',6))"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "users to\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}